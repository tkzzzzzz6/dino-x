import streamlit as st
import cv2
import numpy as np
import time
import os
from PIL import Image
import io
import base64
import json
from dotenv import load_dotenv

# Import custom modules
from dinox_api import detect_objects, encode_image_to_base64
from visualization import visualize_detection_results, create_detection_summary

# Load environment variables
load_dotenv()

# Set page configuration
st.set_page_config(
    page_title="DINO-X å›¾åƒæ£€æµ‹",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Add custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #4CAF50;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #2196F3;
        margin-bottom: 1rem;
    }
    .info-text {
        font-size: 1rem;
        color: #555;
    }
    .highlight {
        background-color: #f0f0f0;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .detection-summary {
        background-color: #e6f7ff;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-top: 1rem;
    }
    .stButton button {
        background-color: #4CAF50;
        color: white;
    }
    .top-objects {
        background-color: #f9f9f9;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'detection_results' not in st.session_state:
    st.session_state.detection_results = None
if 'session_id' not in st.session_state:
    st.session_state.session_id = None
if 'last_detection_time' not in st.session_state:
    st.session_state.last_detection_time = None
if 'uploaded_image' not in st.session_state:
    st.session_state.uploaded_image = None
if 'processed_image' not in st.session_state:
    st.session_state.processed_image = None

# Main application header
st.markdown("<h1 class='main-header'>DINO-X å›¾åƒæ£€æµ‹</h1>", unsafe_allow_html=True)

# Create sidebar for configuration
with st.sidebar:
    st.markdown("<h2 class='sub-header'>é…ç½®</h2>", unsafe_allow_html=True)
    
    # API information
    st.info('DINO-X API è®¾è®¡ä¸ºä¸€æ¬¡å¤„ç†ä¸€å¼ å›¾ç‰‡ã€‚ä¸Šä¼ å›¾ç‰‡å¹¶ç‚¹å‡»"åˆ†æå›¾åƒ"æŒ‰é’®è¿›è¡Œæ£€æµ‹ã€‚')
    
    # API token status
    token_status = "å·²è®¾ç½® âœ…" if os.getenv("DINOX_API_TOKEN") else "æœªè®¾ç½® âŒ"
    st.warning(f"API ä»¤ç‰ŒçŠ¶æ€: {token_status}")
    
    if not os.getenv("DINOX_API_TOKEN"):
        api_token = st.text_input("è¾“å…¥ API ä»¤ç‰Œ", type="password")
        if api_token:
            os.environ["DINOX_API_TOKEN"] = api_token
            st.success("API ä»¤ç‰Œå·²è®¾ç½®ï¼è¯·åˆ·æ–°é¡µé¢ã€‚")
            st.experimental_rerun()
    else:
        # Add API token validation
        if st.button("éªŒè¯ API ä»¤ç‰Œ", key="validate_token"):
            try:
                # Create a simple test image
                test_image = np.zeros((100, 100, 3), dtype=np.uint8)
                test_image[40:60, 40:60] = [255, 255, 255]  # White square
                
                # Test API connection
                with st.spinner("æ­£åœ¨éªŒè¯ API ä»¤ç‰Œ..."):
                    result, _ = detect_objects(
                        test_image,
                        prompt_type="universal",
                        prompt_universal=1,
                        targets=["bbox"],
                        bbox_threshold=0.1
                    )
                
                st.success("API ä»¤ç‰Œæœ‰æ•ˆï¼")
            except Exception as e:
                st.error(f"API ä»¤ç‰ŒéªŒè¯å¤±è´¥: {str(e)}")
                if "401" in str(e):
                    st.error("é”™è¯¯ 401: æœªæˆæƒã€‚è¯·æ£€æŸ¥æ‚¨çš„ API ä»¤ç‰Œæ˜¯å¦æ­£ç¡®ã€‚")
                elif "403" in str(e):
                    st.error("é”™è¯¯ 403: ç¦æ­¢è®¿é—®ã€‚æ‚¨çš„ API ä»¤ç‰Œå¯èƒ½æ²¡æœ‰è¶³å¤Ÿçš„æƒé™ã€‚")
                elif "429" in str(e):
                    st.error("é”™è¯¯ 429: è¯·æ±‚è¿‡å¤šã€‚æ‚¨å·²è¶…å‡º API è°ƒç”¨é™åˆ¶ï¼Œè¯·ç¨åå†è¯•ã€‚")
        
        # Add option to change API token
        if st.checkbox("æ›´æ”¹ API ä»¤ç‰Œ", value=False):
            new_api_token = st.text_input("è¾“å…¥æ–°çš„ API ä»¤ç‰Œ", type="password")
            if new_api_token:
                os.environ["DINOX_API_TOKEN"] = new_api_token
                st.success("API ä»¤ç‰Œå·²æ›´æ–°ï¼è¯·åˆ·æ–°é¡µé¢ã€‚")
                st.experimental_rerun()
    
    # Prompt type
    st.markdown("<h3>æ£€æµ‹å‚æ•°</h3>", unsafe_allow_html=True)
    prompt_type = st.radio("æç¤ºç±»å‹", ["æ–‡æœ¬æç¤º", "é€šç”¨æç¤º"], index=0)
    prompt_type_value = "text" if prompt_type == "æ–‡æœ¬æç¤º" else "universal"
    
    # Text prompt
    if prompt_type == "æ–‡æœ¬æç¤º":
        # Add preset prompts
        preset_prompts = {
            "äººç‰©æ£€æµ‹": "person.man.woman.child",
            "äººç‰©å’Œé…ä»¶": "person.man.woman.child.glasses.hat.headphones",
            "å¸¸è§ç‰©å“": "person.car.dog.cat.chair.table.phone.laptop",
            "å®¤å†…åœºæ™¯": "person.chair.table.sofa.tv.laptop.phone.cup",
            "è‡ªå®šä¹‰": "custom"
        }
        
        selected_preset = st.selectbox("é€‰æ‹©é¢„è®¾æç¤ºè¯", list(preset_prompts.keys()))
        
        if selected_preset == "è‡ªå®šä¹‰":
            prompt_text = st.text_input("æ–‡æœ¬æç¤º (ç”¨ç‚¹å·åˆ†éš”)", "person.headphones.man")
        else:
            prompt_text = preset_prompts[selected_preset]
            st.info(f"å½“å‰æç¤ºè¯: {prompt_text}")
    else:
        prompt_text = None
    
    # Detection targets
    st.markdown("<h3>æ£€æµ‹ç›®æ ‡</h3>", unsafe_allow_html=True)
    
    # ç®€åŒ–ä¸ºåªæœ‰è¾¹ç•Œæ¡†æ£€æµ‹
    bbox = st.checkbox("è¾¹ç•Œæ¡†", value=True, key="target_bbox")
    
    # å§‹ç»ˆåŒ…å«bboxç›®æ ‡
    targets = ["bbox"]
    
    # ç½®ä¿¡åº¦é˜ˆå€¼
    confidence_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.25, 0.05)
    
    # ç®€åŒ–å¯è§†åŒ–é€‰é¡¹ï¼Œåªä¿ç•™è¾¹ç•Œæ¡†æ˜¾ç¤º
    st.markdown("<h3>å¯è§†åŒ–é€‰é¡¹</h3>", unsafe_allow_html=True)
    show_bbox = st.checkbox("æ˜¾ç¤ºè¾¹ç•Œæ¡†", value=True, key="show_bbox")
    show_caption = st.checkbox("æ˜¾ç¤ºæè¿°", value=True, key="show_caption")

# Create main content area with two columns
col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("<h2 class='sub-header'>ä¸Šä¼ å›¾åƒ</h2>", unsafe_allow_html=True)
    
    # ä½¿ç”¨å•é€‰æŒ‰é’®æ›¿ä»£tabs
    input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["ä¸Šä¼ å›¾åƒæ–‡ä»¶", "è¾“å…¥å›¾åƒ URL"])
    
    if input_method == "ä¸Šä¼ å›¾åƒæ–‡ä»¶":
        # Image upload
        uploaded_file = st.file_uploader("é€‰æ‹©å›¾åƒæ–‡ä»¶", type=["jpg", "jpeg", "png"])
        
        if uploaded_file is not None:
            try:
                # Read the image
                image = Image.open(uploaded_file)
                
                # Convert to numpy array for processing
                image_np = np.array(image)
                
                # Store the image in session state
                st.session_state.uploaded_image = image_np
                
                # Display the image
                st.image(image_np, caption="ä¸Šä¼ çš„å›¾åƒ", use_column_width=True)
                
                # Image adjustments
                st.markdown("<h3>å›¾åƒè°ƒæ•´</h3>", unsafe_allow_html=True)
                
                # Add auto-enhance option
                auto_enhance = st.checkbox("è‡ªåŠ¨å¢å¼ºå›¾åƒ", value=False, help="è‡ªåŠ¨è°ƒæ•´äº®åº¦ã€å¯¹æ¯”åº¦å’Œé”åº¦ä»¥æé«˜æ£€æµ‹æˆåŠŸç‡")

                if auto_enhance:
                    # Apply automatic image enhancement
                    # Convert to LAB color space for better enhancement
                    lab = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)
                    # Split the LAB channels
                    l, a, b = cv2.split(lab)
                    # Apply CLAHE to L channel
                    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
                    cl = clahe.apply(l)
                    # Merge the enhanced L channel with the original A and B channels
                    enhanced_lab = cv2.merge((cl, a, b))
                    # Convert back to RGB
                    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)
                    
                    # Apply sharpening
                    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
                    enhanced_image = cv2.filter2D(enhanced_image, -1, kernel * 0.5)
                    
                    # Store the enhanced image
                    st.session_state.processed_image = enhanced_image
                    
                    # Display the enhanced image
                    st.image(enhanced_image, caption="è‡ªåŠ¨å¢å¼ºåçš„å›¾åƒ", use_column_width=True)
                else:
                    # Manual adjustments
                    # Create columns for adjustment controls
                    adj_col1, adj_col2 = st.columns(2)
                    
                    with adj_col1:
                        # Brightness adjustment
                        brightness = st.slider("äº®åº¦", -100, 100, 0, 5)
                        
                        # Contrast adjustment
                        contrast = st.slider("å¯¹æ¯”åº¦", -100, 100, 0, 5)
                    
                    with adj_col2:
                        # Saturation adjustment
                        saturation = st.slider("é¥±å’Œåº¦", -100, 100, 0, 5)
                        
                        # Sharpness adjustment
                        sharpness = st.slider("é”åº¦", 0, 100, 0, 5)
                    
                    # Apply adjustments to the image
                    adjusted_image = image_np.copy()
                    
                    # Apply brightness adjustment
                    if brightness != 0:
                        hsv = cv2.cvtColor(adjusted_image, cv2.COLOR_RGB2HSV)
                        h, s, v = cv2.split(hsv)
                        
                        if brightness > 0:
                            v = np.clip(v + brightness * 2.55, 0, 255).astype(np.uint8)
                        else:
                            v = np.clip(v - abs(brightness) * 2.55, 0, 255).astype(np.uint8)
                        
                        hsv = cv2.merge((h, s, v))
                        adjusted_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
                    
                    # Apply contrast adjustment
                    if contrast != 0:
                        f = 131 * (contrast + 127) / (127 * (131 - contrast))
                        alpha_c = f
                        gamma_c = 127 * (1 - f)
                        
                        adjusted_image = cv2.addWeighted(adjusted_image, alpha_c, adjusted_image, 0, gamma_c)
                    
                    # Apply saturation adjustment
                    if saturation != 0:
                        hsv = cv2.cvtColor(adjusted_image, cv2.COLOR_RGB2HSV)
                        h, s, v = cv2.split(hsv)
                        
                        if saturation > 0:
                            s = np.clip(s + saturation * 2.55, 0, 255).astype(np.uint8)
                        else:
                            s = np.clip(s - abs(saturation) * 2.55, 0, 255).astype(np.uint8)
                        
                        hsv = cv2.merge((h, s, v))
                        adjusted_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
                    
                    # Apply sharpness adjustment
                    if sharpness > 0:
                        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
                        adjusted_image = cv2.filter2D(adjusted_image, -1, kernel * (sharpness / 100))
                    
                    # Store the adjusted image
                    st.session_state.processed_image = adjusted_image
                    
                    # Display the adjusted image if any adjustments were made
                    if brightness != 0 or contrast != 0 or saturation != 0 or sharpness > 0:
                        st.image(adjusted_image, caption="è°ƒæ•´åçš„å›¾åƒ", use_column_width=True)

                # Add image resize option
                resize_image = st.checkbox("è°ƒæ•´å›¾åƒå°ºå¯¸", value=False, help="è°ƒæ•´å›¾åƒå°ºå¯¸å¯èƒ½ä¼šå½±å“æ£€æµ‹æ•ˆæœ")

                if resize_image:
                    # Get the current image
                    current_image = st.session_state.processed_image if st.session_state.processed_image is not None else image_np
                    
                    # Get original dimensions
                    h, w = current_image.shape[:2]
                    
                    # Create a slider for resize factor
                    resize_factor = st.slider("è°ƒæ•´æ¯”ä¾‹", 0.1, 2.0, 1.0, 0.1)
                    
                    if resize_factor != 1.0:
                        # Calculate new dimensions
                        new_w = int(w * resize_factor)
                        new_h = int(h * resize_factor)
                        
                        # Resize the image
                        resized_image = cv2.resize(current_image, (new_w, new_h))
                        
                        # Store the resized image
                        st.session_state.processed_image = resized_image
                        
                        # Display the resized image
                        st.image(resized_image, caption=f"è°ƒæ•´åçš„å›¾åƒ ({new_w}x{new_h})", use_column_width=True)

                # Add a button to analyze the image
                if st.button("ğŸ” åˆ†æå›¾åƒ", key="analyze_image", use_container_width=True):
                    with st.spinner("æ­£åœ¨åˆ†æå›¾åƒ..."):
                        # Record start time
                        start_time = time.time()
                        
                        # Get the image to analyze
                        image_to_analyze = st.session_state.processed_image if st.session_state.processed_image is not None else st.session_state.uploaded_image
                        
                        # Perform detection
                        prompt_universal = 1 if prompt_type_value == "universal" else None
                        result, session_id = detect_objects(
                            image_to_analyze,
                            prompt_type=prompt_type_value,
                            prompt_text=prompt_text,
                            prompt_universal=prompt_universal,
                            targets=["bbox"],  # åªä½¿ç”¨è¾¹ç•Œæ¡†æ£€æµ‹
                            bbox_threshold=confidence_threshold
                        )
                        
                        # Calculate detection time
                        detection_time = time.time() - start_time
                        
                        # Store results in session state
                        st.session_state.detection_results = result
                        st.session_state.session_id = session_id
                        st.session_state.last_detection_time = detection_time
                        
                        # Show success message
                        if "objects" in result and result["objects"]:
                            st.success(f"æˆåŠŸæ£€æµ‹åˆ° {len(result['objects'])} ä¸ªå¯¹è±¡ï¼")
                        else:
                            st.warning("æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ã€‚å°è¯•è°ƒæ•´æç¤ºè¯æˆ–é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ã€‚")

                # Add a button for universal detection (fallback)
                if st.button("ğŸŒ é€šç”¨æ£€æµ‹ (æ£€æµ‹æ‰€æœ‰ç‰©ä½“)", key="universal_detection", use_container_width=True):
                    with st.spinner("æ­£åœ¨è¿›è¡Œé€šç”¨æ£€æµ‹..."):
                        # Record start time
                        start_time = time.time()
                        
                        # Get the image to analyze
                        image_to_analyze = st.session_state.processed_image if st.session_state.processed_image is not None else st.session_state.uploaded_image
                        
                        # åªä½¿ç”¨è¾¹ç•Œæ¡†æ£€æµ‹
                        bbox_targets = ["bbox"]
                        
                        # Perform detection with universal mode
                        result, session_id = detect_objects(
                            image_to_analyze,
                            prompt_type="universal",
                            prompt_universal=1,
                            targets=bbox_targets,  # åªä½¿ç”¨è¾¹ç•Œæ¡†æ£€æµ‹
                            bbox_threshold=0.05  # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼
                        )
                        
                        # Calculate detection time
                        detection_time = time.time() - start_time
                        
                        # Store results in session state
                        st.session_state.detection_results = result
                        st.session_state.session_id = session_id
                        st.session_state.last_detection_time = detection_time
                        
                        # Show success message
                        if "objects" in result and result["objects"]:
                            st.success(f"æˆåŠŸæ£€æµ‹åˆ° {len(result['objects'])} ä¸ªå¯¹è±¡ï¼")
                        else:
                            st.error("é€šç”¨æ£€æµ‹ä¹Ÿæœªèƒ½æ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ã€‚è¯·æ£€æŸ¥å›¾åƒè´¨é‡æˆ– API è¿æ¥ã€‚")
            
            except Exception as e:
                st.error(f"å¤„ç†å›¾åƒæ—¶å‡ºé”™: {str(e)}")
                import traceback
                st.error(traceback.format_exc())
    
    elif input_method == "è¾“å…¥å›¾åƒ URL":
        # Image URL input
        image_url = st.text_input("è¾“å…¥å›¾åƒ URL", "")
        
        if image_url:
            try:
                # Add a button to fetch the image
                if st.button("è·å–å›¾åƒ", key="fetch_image"):
                    with st.spinner("æ­£åœ¨è·å–å›¾åƒ..."):
                        # Download the image
                        import requests
                        from io import BytesIO
                        
                        response = requests.get(image_url)
                        if response.status_code != 200:
                            st.error(f"è·å–å›¾åƒå¤±è´¥: HTTP çŠ¶æ€ç  {response.status_code}")
                        else:
                            # Open the image
                            image = Image.open(BytesIO(response.content))
                            
                            # Convert to numpy array for processing
                            image_np = np.array(image)
                            
                            # Store the image in session state
                            st.session_state.uploaded_image = image_np
                            
                            # Display the image
                            st.image(image_np, caption="ä» URL è·å–çš„å›¾åƒ", use_column_width=True)
            except Exception as e:
                st.error(f"å¤„ç†å›¾åƒ URL æ—¶å‡ºé”™: {str(e)}")

    # Check if an image is uploaded or fetched
    if 'uploaded_image' in st.session_state and st.session_state.uploaded_image is not None:
        # Image adjustments
        st.markdown("<h3>å›¾åƒè°ƒæ•´</h3>", unsafe_allow_html=True)

with col2:
    st.markdown("<h2 class='sub-header'>æ£€æµ‹ç»“æœ</h2>", unsafe_allow_html=True)
    
    # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
    if 'detection_results' in st.session_state and st.session_state.detection_results:
        result = st.session_state.detection_results
        
        # æ˜¾ç¤ºæ£€æµ‹æ—¶é—´
        if 'last_detection_time' in st.session_state:
            st.info(f"æ£€æµ‹è€—æ—¶: {st.session_state.last_detection_time:.2f} ç§’")
        
        # æ˜¾ç¤ºä¼šè¯ID
        if 'session_id' in st.session_state and st.session_state.session_id:
            st.info(f"ä¼šè¯ ID: {st.session_state.session_id}")
        
        # æ˜¾ç¤ºæ£€æµ‹ç»“æœæ‘˜è¦
        if "objects" in result and result["objects"]:
            st.success(f"æ£€æµ‹åˆ° {len(result['objects'])} ä¸ªå¯¹è±¡")
            
            # æ˜¾ç¤ºæ£€æµ‹ç»“æœå¯è§†åŒ–
            if 'uploaded_image' in st.session_state and st.session_state.uploaded_image is not None:
                # è·å–åŸå§‹å›¾åƒ
                original_image = st.session_state.processed_image if st.session_state.processed_image is not None else st.session_state.uploaded_image
                
                # ç®€åŒ–æ˜¾ç¤ºé€‰é¡¹ï¼Œåªä¿ç•™è¾¹ç•Œæ¡†å’Œæè¿°
                st.markdown("<h3>æ˜¾ç¤ºé€‰é¡¹</h3>", unsafe_allow_html=True)
                result_show_bbox = st.checkbox("æ˜¾ç¤ºè¾¹ç•Œæ¡†", value=True, key="result_show_bbox")
                result_show_caption = st.checkbox("æ˜¾ç¤ºæè¿°", value=True, key="result_show_caption")
                
                # å¯è§†åŒ–æ£€æµ‹ç»“æœï¼Œåªä½¿ç”¨è¾¹ç•Œæ¡†å’Œæè¿°
                visualized_image = visualize_detection_results(
                    original_image, 
                    result["objects"],
                    show_bbox=result_show_bbox,
                    show_mask=False,  # ä¸æ˜¾ç¤ºæ©ç 
                    show_pose=False,  # ä¸æ˜¾ç¤ºå§¿æ€
                    show_hand=False,  # ä¸æ˜¾ç¤ºæ‰‹éƒ¨
                    show_caption=result_show_caption
                )
                
                # æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
                st.image(visualized_image, caption="æ£€æµ‹ç»“æœ", use_column_width=True)
                
                # æ·»åŠ ä¿å­˜æŒ‰é’®
                if st.button("ğŸ’¾ ä¿å­˜ç»“æœ", key="save_image", use_container_width=True):
                    try:
                        # Convert the visualized image to PIL Image
                        pil_image = Image.fromarray(visualized_image)
                        
                        # Create a BytesIO object
                        buf = io.BytesIO()
                        pil_image.save(buf, format="PNG")
                        
                        # Get the byte value
                        byte_im = buf.getvalue()
                        
                        # Create a download button
                        timestamp = time.strftime("%Y%m%d-%H%M%S")
                        filename = f"dinox_analysis_{timestamp}.png"
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½å›¾åƒ",
                            data=byte_im,
                            file_name=filename,
                            mime="image/png",
                            key="download_button"
                        )
                        
                        st.success(f"å›¾åƒå·²å‡†å¤‡å¥½ä¸‹è½½: {filename}")
                    except Exception as e:
                        st.error(f"ä¿å­˜å›¾åƒæ—¶å‡ºé”™: {str(e)}")
                
                # æ˜¾ç¤ºæ£€æµ‹ç»“æœè¯¦æƒ…
                with st.expander("æ£€æµ‹ç»“æœè¯¦æƒ…", expanded=False):
                    summary = create_detection_summary(result["objects"])
                    st.markdown(summary)

                # æ˜¾ç¤ºåŸå§‹JSONç»“æœï¼ˆä½œä¸ºå•ç‹¬çš„expanderï¼Œä¸åµŒå¥—ï¼‰
                with st.expander("åŸå§‹JSONç»“æœ", expanded=False):
                    st.json(result)
            else:
                st.warning("æ— æ³•æ˜¾ç¤ºæ£€æµ‹ç»“æœå¯è§†åŒ–ï¼Œå› ä¸ºæ²¡æœ‰ä¸Šä¼ å›¾åƒ")
        else:
            st.warning("æœªæ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡")
    else:
        st.info("è¯·ä¸Šä¼ å›¾åƒå¹¶ç‚¹å‡»åˆ†ææŒ‰é’®")
    
    # Add debug information
    with st.expander("è°ƒè¯•ä¿¡æ¯"):
        st.markdown("### API è°ƒç”¨ä¿¡æ¯")
        st.write("API ä»¤ç‰ŒçŠ¶æ€:", "å·²è®¾ç½®" if os.getenv("DINOX_API_TOKEN") else "æœªè®¾ç½®")
        st.write("æç¤ºç±»å‹:", prompt_type_value)
        if prompt_type_value == "text":
            st.write("æç¤ºæ–‡æœ¬:", prompt_text)
        else:
            st.write("é€šç”¨æç¤ºå€¼:", "1 (ç²—åŠ›åº¦æ£€æµ‹ä¸‡ç‰©)")
        st.write("æ£€æµ‹ç›®æ ‡:", targets)
        st.write("ç½®ä¿¡åº¦é˜ˆå€¼:", confidence_threshold)
        
        if st.session_state.last_detection_time is not None:
            st.write("æ£€æµ‹æ—¶é—´:", f"{st.session_state.last_detection_time:.2f} ç§’")
        
        if st.session_state.session_id:
            st.write("ä¼šè¯ ID:", st.session_state.session_id)
        
        # Add a button to test API connection
        if st.button("æµ‹è¯• API è¿æ¥", key="test_api"):
            try:
                # Create a simple test image
                test_image = np.zeros((100, 100, 3), dtype=np.uint8)
                test_image[40:60, 40:60] = [255, 255, 255]  # White square
                
                # Test API connection
                with st.spinner("æ­£åœ¨æµ‹è¯• API è¿æ¥..."):
                    result, _ = detect_objects(
                        test_image,
                        prompt_type="universal",
                        prompt_universal=1,
                        targets=["bbox"],
                        bbox_threshold=0.1
                    )
                
                st.success("API è¿æ¥æˆåŠŸ!")
                st.write("API å“åº”:", result)
            except Exception as e:
                st.error(f"API è¿æ¥å¤±è´¥: {str(e)}")
                import traceback
                st.code(traceback.format_exc())

# Add information about the application
st.markdown("<h2 class='sub-header'>å…³äº</h2>", unsafe_allow_html=True)
st.markdown("""
<div class='highlight'>
    <p class='info-text'>
        æœ¬æ¼”ç¤ºåº”ç”¨ä½¿ç”¨ DINO-X API è¿›è¡Œå›¾åƒå¯¹è±¡æ£€æµ‹ã€åˆ†å‰²ã€å§¿æ€ä¼°è®¡ç­‰ã€‚
        DINO-X æ”¯æŒå¼€æ”¾é›†ç›®æ ‡æ£€æµ‹ä¸åˆ†å‰²ã€çŸ­è¯­å®šä½ã€è§†è§‰æç¤ºè®¡æ•°å’Œå§¿æ€ä¼°è®¡ã€‚
    </p>
    <p class='info-text'>
        <b>ä½¿ç”¨æ–¹æ³•ï¼š</b>
        1. ä¸Šä¼ å›¾åƒæ–‡ä»¶
        2. é…ç½®æ£€æµ‹å‚æ•°ï¼ˆæç¤ºç±»å‹ã€æ£€æµ‹ç›®æ ‡ç­‰ï¼‰
        3. è°ƒæ•´å›¾åƒå‚æ•°ï¼ˆå¯é€‰ï¼‰
        4. ç‚¹å‡»'åˆ†æå›¾åƒ'æŒ‰é’®
        5. æŸ¥çœ‹æ£€æµ‹ç»“æœå’Œåˆ†æ
    </p>
    <p class='info-text'>
        <b>åŠŸèƒ½ç‰¹ç‚¹ï¼š</b>
        â€¢ å›¾åƒä¸Šä¼ å’Œè°ƒæ•´
        â€¢ å¤šç§æ£€æµ‹ç›®æ ‡ï¼šè¾¹ç•Œæ¡†ã€åˆ†å‰²æ©ç ã€å§¿æ€å…³é”®ç‚¹ã€æ‰‹éƒ¨å…³é”®ç‚¹
        â€¢ å¯è§†åŒ–æ£€æµ‹ç»“æœ
        â€¢ ç»“æœä¿å­˜å’Œä¸‹è½½
        â€¢ è¯¦ç»†çš„æ£€æµ‹æ‘˜è¦
    </p>
</div>
""", unsafe_allow_html=True)

# Create a footer with API information
st.markdown("""
<div style="margin-top: 50px; text-align: center; color: #888;">
    <p>DINO-X API ç”± DeepDataSpace æä¾›</p>
    <p>æœ¬åº”ç”¨ç¨‹åºä»…ç”¨äºæ¼”ç¤ºç›®çš„</p>
</div>
""", unsafe_allow_html=True)

# åœ¨é¡µé¢æœ€åº•éƒ¨æ·»åŠ è®¿é—®è®¡æ•°ç»„ä»¶
st.markdown("<hr>", unsafe_allow_html=True)
st.markdown("""
<div style="text-align: center; margin-top: 20px; margin-bottom: 20px;">
    <span>
        <img src="https://count.getloli.com/@tkzzzzzz6?name=tkzzzzzz6&theme=rule34&padding=8&offset=0&align=top&scale=1&pixelated=1&darkmode=auto" alt="è®¿é—®è®¡æ•°" />
    </span>
</div>
<div style="text-align: center; font-size: 12px; color: #888;">
    Â© 2025 Ke Tan ->DINO-X å›¾åƒåˆ†æå·¥å…· | ç”± Streamlit æä¾›æ”¯æŒ
</div>
""", unsafe_allow_html=True) 